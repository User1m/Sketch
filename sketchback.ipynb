{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using TensorFlow backend.\n"
     ]
    }
   ],
   "source": [
    "from __future__ import print_function\n",
    "import numpy as np\n",
    "import pandas as pd \n",
    "import cv2 as cv\n",
    "import os\n",
    "import h5py\n",
    "import matplotlib.pyplot as plt\n",
    "import scipy.misc\n",
    "import scipy.ndimage\n",
    "\n",
    "from tqdm import tqdm\n",
    "from copy import deepcopy\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from keras.models import Sequential, Model\n",
    "from keras.layers import Input, Dense, Conv2D, MaxPooling2D, UpSampling2D, ZeroPadding2D, Convolution2D, Deconvolution2D, merge\n",
    "from keras.layers.core import Activation, Dropout, Flatten, Lambda\n",
    "from keras.layers.normalization import BatchNormalization\n",
    "from keras.optimizers import SGD, Adam, Nadam\n",
    "from keras.utils import np_utils\n",
    "from keras.callbacks import TensorBoard\n",
    "from keras import objectives, layers\n",
    "from keras.applications import vgg16\n",
    "from keras.applications.vgg16 import preprocess_input\n",
    "from keras import backend as K\n",
    "import cv2\n",
    "from PIL import Image\n",
    "from scipy.misc import imresize\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "\n",
    "np.random.seed(1337)  # for reproducibility"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Anaconda3\\envs\\tensorflow-gpu\\lib\\site-packages\\ipykernel_launcher.py:2: UserWarning: Update your `Model` call to the Keras 2 API: `Model(inputs=Tensor(\"in..., outputs=Tensor(\"bl...)`\n",
      "  \n"
     ]
    }
   ],
   "source": [
    "base_model = vgg16.VGG16(weights='imagenet', include_top=False)\n",
    "vgg = Model(input=base_model.input, output=base_model.get_layer('block2_conv2').output)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# def load_file_names(path):\n",
    "#     return os.listdir(path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def imshow(x, gray=False):\n",
    "    plt.imshow(x, cmap='gray' if gray else None)\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def get_features(Y):\n",
    "    Z = deepcopy(Y)\n",
    "    Z = preprocess_vgg(Z)\n",
    "    features = vgg.predict(Z, batch_size = 5, verbose = 0)\n",
    "    return features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def preprocess_vgg(x, data_format=None):\n",
    "    if data_format is None:\n",
    "        data_format = K.image_data_format()\n",
    "    assert data_format in {'channels_last', 'channels_first'}\n",
    "    x = 255. * x\n",
    "    if data_format == 'channels_first':\n",
    "        # 'RGB'->'BGR'\n",
    "        x = x[:, ::-1, :, :]\n",
    "        # Zero-center by mean pixel\n",
    "        x[:, 0, :, :] = x[:, 0, :, :] - 103.939\n",
    "        x[:, 1, :, :] = x[:, 1, :, :] - 116.779\n",
    "        x[:, 2, :, :] = x[:, 2, :, :] - 123.68\n",
    "    else:\n",
    "        # 'RGB'->'BGR'\n",
    "        x = x[:, :, :, ::-1]\n",
    "        # Zero-center by mean pixel\n",
    "        x[:, :, :, 0] = x[:, :, :, 0] - 103.939\n",
    "        x[:, :, :, 1] = x[:, :, :, 1] - 116.779\n",
    "        x[:, :, :, 2] = x[:, :, :, 2] - 123.68\n",
    "    return x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def feature_loss(y_true, y_pred):\n",
    "    return K.sqrt(K.mean(K.square(y_true - y_pred)))\n",
    "\n",
    "def pixel_loss(y_true, y_pred):\n",
    "    return K.sqrt(K.mean(K.square(y_true - y_pred))) + 0.00001*total_variation_loss(y_pred)\n",
    "\n",
    "def adv_loss(y_true, y_pred):\n",
    "    return K.mean(K.binary_crossentropy(y_pred, y_true), axis=-1)\n",
    "\n",
    "def total_variation_loss(y_pred):\n",
    "    if K.image_data_format() == 'channels_first':\n",
    "        a = K.square(y_pred[:, :, :m - 1, :n - 1] - y_pred[:, :, 1:, :n - 1])\n",
    "        b = K.square(y_pred[:, :, :m - 1, :n - 1] - y_pred[:, :, :m - 1, 1:])\n",
    "    else:\n",
    "        a = K.square(y_pred[:, :m - 1, :n - 1, :] - y_pred[:, 1:, :n - 1, :])\n",
    "        b = K.square(y_pred[:, :m - 1, :n - 1, :] - y_pred[:, :m - 1, 1:, :])\n",
    "    return K.sum(K.pow(a + b, 1.25))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def preprocess_VGG(x, dim_ordering='default'):\n",
    "    if dim_ordering == 'default':\n",
    "        dim_ordering = K.image_dim_ordering()\n",
    "    assert dim_ordering in {'tf', 'th'}\n",
    "    # x has pixels intensities between 0 and 1\n",
    "    x = 255. * x\n",
    "    norm_vec = K.variable([103.939, 116.779, 123.68])\n",
    "    if dim_ordering == 'th':\n",
    "        norm_vec = K.reshape(norm_vec, (1,3,1,1))\n",
    "        x = x - norm_vec\n",
    "        # 'RGB'->'BGR'\n",
    "        x = x[:, ::-1, :, :]\n",
    "    else:\n",
    "        norm_vec = K.reshape(norm_vec, (1,1,1,3))\n",
    "        x = x - norm_vec\n",
    "        # 'RGB'->'BGR'\n",
    "        x = x[:, :, :, ::-1]\n",
    "    return x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def generator_model(input_img):\n",
    "\n",
    "    # Encoder\n",
    "    x = Conv2D(32, (3, 3), activation='relu', padding='same')(input_img)\n",
    "    x = Conv2D(32, (2, 2), activation='relu', padding='same')(x)\n",
    "    x = MaxPooling2D((2, 2), padding='same')(x)\n",
    "\n",
    "    x = Conv2D(64, (3, 3), activation='relu', padding='same', name='block2_conv1')(x)\n",
    "    x = Conv2D(64, (2, 2), activation='relu', padding='same')(x)\n",
    "    x = MaxPooling2D((2, 2), padding='same')(x)\n",
    "\n",
    "    x = Conv2D(128, (3, 3), activation='relu', padding='same', name='block3_conv1')(x)\n",
    "    x = Conv2D(128, (3, 3), activation='relu', padding='same')(x)\n",
    "    x = MaxPooling2D((2, 2), padding='same')(x)\n",
    "\n",
    "    x = Conv2D(256, (3, 3), activation='relu', padding='same', name='block4_conv1')(x)\n",
    "    res = Conv2D(256, (3, 3), activation='relu', padding='same')(x)\n",
    "    x = layers.add([x, res])\n",
    "    res = Conv2D(256, (3, 3), activation='relu', padding='same')(x)\n",
    "    encoded = layers.add([x, res])\n",
    "\n",
    "    # Decoder\n",
    "    res = Conv2D(256, (3, 3), activation='relu', padding='same', name='block5_conv1')(encoded)\n",
    "    x = layers.add([encoded, res])\n",
    "    res = Conv2D(256, (3, 3), activation='relu', padding='same')(x)\n",
    "    x = layers.add([x, res])\n",
    "    res = Conv2D(256, (3, 3), activation='relu', padding='same')(x)\n",
    "    x = layers.add([x, res])\n",
    "\n",
    "    x = Conv2D(128, (2, 2), activation='relu', padding='same', name='block6_conv1')(x)\n",
    "    x = UpSampling2D((2, 2))(x)\n",
    "\n",
    "    x = Conv2D(128, (3, 3), activation='relu', padding='same', name='block7_conv1')(x)\n",
    "    res = Conv2D(128, (3, 3), activation='relu', padding='same')(x)\n",
    "    x = layers.add([x, res])\n",
    "    res = Conv2D(128, (3, 3), activation='relu', padding='same')(x)\n",
    "    x = layers.add([x, res])\n",
    "\n",
    "    x = Conv2D(64, (2, 2), activation='relu', padding='same', name='block8_conv1')(x)\n",
    "    x = UpSampling2D((2, 2))(x)\n",
    "\n",
    "    x = Conv2D(64, (3, 3), activation='relu', padding='same', name='block9_conv1')(x)\n",
    "    res = Conv2D(64, (3, 3), activation='relu', padding='same')(x)\n",
    "    x = layers.add([x, res])\n",
    "    res = Conv2D(64, (3, 3), activation='relu', padding='same')(x)\n",
    "    x = layers.add([x, res])\n",
    "\n",
    "    x = Conv2D(32, (2, 2), activation='relu', padding='same', name='block10_conv1')(x)\n",
    "    x = UpSampling2D((2, 2))(x)\n",
    "\n",
    "    x = Conv2D(32, (3, 3), activation='relu', padding='same', name='block11_conv1')(x)\n",
    "    res = Conv2D(32, (3, 3), activation='relu', padding='same')(x)\n",
    "    x = layers.add([x, res])\n",
    "    decoded = Conv2D(3, (3, 3), activation='sigmoid', padding='same')(x)\n",
    "    \n",
    "    return decoded"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def feat_model(img_input):\n",
    "    # extract vgg feature\n",
    "    vgg_16 = vgg16.VGG16(include_top=False, weights='imagenet', input_tensor=None)\n",
    "    # freeze VGG_16 when training\n",
    "    for layer in vgg_16.layers:\n",
    "        layer.trainable = False\n",
    "    \n",
    "    vgg_first2 = Model(input=vgg_16.input, output=vgg_16.get_layer('block2_conv2').output)\n",
    "    Norm_layer = Lambda(preprocess_VGG)\n",
    "    x_VGG = Norm_layer(img_input)\n",
    "    feat = vgg_first2(x_VGG)\n",
    "    return feat"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def full_model():\n",
    "    input_img = Input(shape=(m, n, 1))\n",
    "    generator = generator_model(input_img)\n",
    "    feat = feat_model(generator)\n",
    "    model = Model(input=input_img, output=[generator, feat], name='architect')\n",
    "    return model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def compute_vgg():\n",
    "    base_model = vgg16.VGG16(weights='imagenet', include_top=False)\n",
    "    model = Model(input=base_model.input, output=base_model.get_layer('block2_conv2').output)\n",
    "    num_batches = num_images // batch_size\n",
    "    for batch in range(num_batches):\n",
    "        _, Y = get_batch(batch, X = False);\n",
    "        Y = preprocess_vgg(Y)\n",
    "        features = model.predict(Y, verbose = 1)\n",
    "        f = h5py.File('features/feat_%d' % batch, \"w\")\n",
    "        dset = f.create_dataset(\"features\", data=features)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Anaconda3\\envs\\tensorflow-gpu\\lib\\site-packages\\ipykernel_launcher.py:8: UserWarning: Update your `Model` call to the Keras 2 API: `Model(inputs=Tensor(\"in..., outputs=Tensor(\"bl...)`\n",
      "  \n",
      "C:\\Anaconda3\\envs\\tensorflow-gpu\\lib\\site-packages\\ipykernel_launcher.py:5: UserWarning: Update your `Model` call to the Keras 2 API: `Model(name=\"architect\", inputs=Tensor(\"in..., outputs=[<tf.Tenso...)`\n",
      "  \"\"\"\n"
     ]
    }
   ],
   "source": [
    "m = 200\n",
    "n = 200\n",
    "sketch_dim = (m,n)\n",
    "img_dim = (m, n,3)\n",
    "model = full_model()\n",
    "optim = Adam(lr=1e-4,beta_1=0.9, beta_2=0.999, epsilon=1e-8)\n",
    "model.compile(loss=[pixel_loss, feature_loss], loss_weights=[1, 1], optimizer=optim)\n",
    "model.load_weights('newWeights/weights_26')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "def predictAndPlot(input_path, label_path):\n",
    "    m = 200\n",
    "    n = 200\n",
    "    sketch_dim = (m,n)\n",
    "    img_dim = (m, n,3)\n",
    "    sketch = cv.imread(input_path, 0)\n",
    "    sketch = imresize(sketch, sketch_dim)\n",
    "    sketch = sketch / 255.\n",
    "    sketch = sketch.reshape(1,m,n,1)\n",
    "    actual = cv.imread(label_path)\n",
    "    actual = imresize(actual, img_dim)\n",
    "    result, _ = model.predict(sketch) \n",
    "    #### Plotting ####\n",
    "    fig = plt.figure()\n",
    "    a = fig.add_subplot(1,3,1)\n",
    "    imgplot = plt.imshow(sketch[0].reshape(m,n), cmap='gray')\n",
    "    a.set_title('Sketch')\n",
    "    plt.axis(\"off\")\n",
    "    a = fig.add_subplot(1,3,2)\n",
    "    imgplot = plt.imshow(result[0])\n",
    "    a.set_title('Prediction')\n",
    "    plt.axis(\"off\")\n",
    "    a = fig.add_subplot(1,3,3)\n",
    "    plt.imshow(cv2.cvtColor(actual, cv2.COLOR_BGR2RGB))\n",
    "    a.set_title('label')\n",
    "    plt.axis(\"off\")\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "#predictAndPlot('rsketch/f1-001-01-sz1.jpg','rphoto/f1-001-01.jpg')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
